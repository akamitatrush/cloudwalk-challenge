{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ CloudWalk Monitoring Analyst Challenge\n",
        "## Task 3.1 - Anomaly Detection Analysis\n",
        "\n",
        "---\n",
        "\n",
        "### üë®‚Äçüíª Candidato: S√©rgio\n",
        "### üìã Vaga: Monitoring Intelligence Analyst (Night Shift)\n",
        "\n",
        "---\n",
        "\n",
        "**Este notebook √© INTERATIVO!** Execute cada c√©lula para ver a an√°lise em tempo real.\n",
        "\n",
        "‚ñ∂Ô∏è Clique em **Runtime > Run all** para executar tudo de uma vez."
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì¶ 1. Setup - Instala√ß√£o e Imports"
      ],
      "metadata": {
        "id": "setup"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "# Instala√ß√£o das depend√™ncias\n",
        "!pip install pandas numpy matplotlib seaborn pandasql plotly -q\n",
        "\n",
        "print(\"‚úÖ Depend√™ncias instaladas com sucesso!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pandasql import sqldf\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Config\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "print(\"‚úÖ Imports carregados!\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä 2. Carregar Dados\n",
        "\n",
        "Os dados representam transa√ß√µes de checkout por hora em dois terminais POS diferentes."
      ],
      "metadata": {
        "id": "data"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dados do checkout_1.csv (DIA NORMAL)\n",
        "checkout_1_data = \"\"\"time,today,yesterday,same_day_last_week,avg_last_week,avg_last_month\n",
        "00h,1,2,1,1.43,1.1\n",
        "01h,0,1,0,0.43,0.37\n",
        "02h,2,0,0,0.29,0.23\n",
        "03h,0,0,0,0.14,0.13\n",
        "04h,0,0,0,0.14,0.23\n",
        "05h,0,0,0,0.14,0.27\n",
        "06h,0,0,1,0.43,0.33\n",
        "07h,1,1,2,1.71,1.2\n",
        "08h,8,5,5,4.57,4.2\n",
        "09h,21,24,17,20.71,18.53\n",
        "10h,55,48,53,49.71,46.77\n",
        "11h,50,51,60,55.0,51.53\n",
        "12h,44,43,51,48.14,46.2\n",
        "13h,40,48,47,49.57,47.13\n",
        "14h,45,43,49,47.71,47.43\n",
        "15h,51,51,52,50.43,49.3\n",
        "16h,41,40,42,44.29,45.2\n",
        "17h,45,46,39,42.29,41.2\n",
        "18h,32,35,32,34.86,36.2\n",
        "19h,24,25,26,28.86,28.2\n",
        "20h,20,21,18,22.57,22.2\n",
        "21h,22,18,17,15.57,16.2\n",
        "22h,16,13,10,11.57,12.2\n",
        "23h,8,8,5,5.43,5.5\"\"\"\n",
        "\n",
        "# Dados do checkout_2.csv (DIA COM ANOMALIA)\n",
        "checkout_2_data = \"\"\"time,today,yesterday,same_day_last_week,avg_last_week,avg_last_month\n",
        "00h,1,2,1,1.43,1.1\n",
        "01h,0,1,0,0.43,0.37\n",
        "02h,4,0,0,0.29,0.23\n",
        "03h,2,0,0,0.14,0.13\n",
        "04h,3,0,0,0.14,0.23\n",
        "05h,5,0,0,0.14,0.27\n",
        "06h,4,0,1,0.43,0.33\n",
        "07h,7,1,2,1.71,1.2\n",
        "08h,25,0,5,3.71,4.2\n",
        "09h,36,2,17,10.14,18.53\n",
        "10h,49,51,53,50.0,46.77\n",
        "11h,51,53,60,55.71,51.53\n",
        "12h,48,45,51,48.71,46.2\n",
        "13h,45,49,47,50.14,47.13\n",
        "14h,19,44,49,19.57,47.43\n",
        "15h,0,51,52,22.43,49.3\n",
        "16h,0,41,42,21.57,45.2\n",
        "17h,0,45,39,17.71,41.2\n",
        "18h,13,34,32,16.86,36.2\n",
        "19h,25,24,26,19.0,28.2\n",
        "20h,27,20,18,19.86,22.2\n",
        "21h,31,17,17,18.14,16.2\n",
        "22h,22,12,10,15.71,12.2\n",
        "23h,10,7,5,8.29,5.5\"\"\"\n",
        "\n",
        "# Carregar em DataFrames\n",
        "from io import StringIO\n",
        "checkout_1 = pd.read_csv(StringIO(checkout_1_data))\n",
        "checkout_2 = pd.read_csv(StringIO(checkout_2_data))\n",
        "\n",
        "# Adicionar coluna de hora num√©rica\n",
        "checkout_1['hour'] = checkout_1['time'].str.replace('h', '').astype(int)\n",
        "checkout_2['hour'] = checkout_2['time'].str.replace('h', '').astype(int)\n",
        "\n",
        "print(\"‚úÖ Dados carregados!\")\n",
        "print(f\"\\nüìä checkout_1: {len(checkout_1)} registros (DIA NORMAL)\")\n",
        "print(f\"üìä checkout_2: {len(checkout_2)} registros (DIA COM ANOMALIA)\")"
      ],
      "metadata": {
        "id": "load_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar os dados\n",
        "print(\"\\nüìã CHECKOUT_1 (Dia Normal):\")\n",
        "display(checkout_1)\n",
        "\n",
        "print(\"\\nüìã CHECKOUT_2 (Dia com Anomalia):\")\n",
        "display(checkout_2)"
      ],
      "metadata": {
        "id": "view_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîç 3. An√°lise SQL Interativa\n",
        "\n",
        "Execute queries SQL diretamente nos dados!"
      ],
      "metadata": {
        "id": "sql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√£o helper para SQL\n",
        "pysqldf = lambda q: sqldf(q, globals())\n",
        "\n",
        "print(\"‚úÖ SQL Engine pronto! Use pysqldf('sua query') para executar.\")"
      ],
      "metadata": {
        "id": "sql_setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# QUERY 1: Detectar TODAS as anomalias no checkout_2\n",
        "query_anomalies = \"\"\"\n",
        "SELECT \n",
        "    time,\n",
        "    today,\n",
        "    yesterday,\n",
        "    ROUND(avg_last_week, 2) as avg_last_week,\n",
        "    ROUND(((today - avg_last_week) / avg_last_week) * 100, 2) AS deviation_pct,\n",
        "    CASE \n",
        "        WHEN today = 0 AND avg_last_week > 5 THEN 'üî¥ CRITICAL - ZERO TX'\n",
        "        WHEN today < avg_last_week * 0.25 THEN 'üü† HIGH - DROP >75%'\n",
        "        WHEN today < avg_last_week * 0.5 THEN 'üü° MEDIUM - DROP >50%'\n",
        "        WHEN today > avg_last_week * 3 THEN 'üü† HIGH - SPIKE >200%'\n",
        "        WHEN today > avg_last_week * 2 THEN 'üü° MEDIUM - SPIKE >100%'\n",
        "        ELSE 'üü¢ NORMAL'\n",
        "    END AS status\n",
        "FROM checkout_2\n",
        "WHERE today = 0 \n",
        "   OR today < avg_last_week * 0.5 \n",
        "   OR today > avg_last_week * 2\n",
        "ORDER BY \n",
        "    CASE \n",
        "        WHEN today = 0 AND avg_last_week > 5 THEN 1\n",
        "        WHEN today < avg_last_week * 0.25 THEN 2\n",
        "        ELSE 3\n",
        "    END,\n",
        "    hour\n",
        "\"\"\"\n",
        "\n",
        "print(\"üîç QUERY 1: Detec√ß√£o de Anomalias no checkout_2\")\n",
        "print(\"=\"*60)\n",
        "anomalies = pysqldf(query_anomalies)\n",
        "display(anomalies)"
      ],
      "metadata": {
        "id": "query1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# QUERY 2: Compara√ß√£o de totais di√°rios\n",
        "query_comparison = \"\"\"\n",
        "SELECT \n",
        "    'checkout_1' as dataset,\n",
        "    SUM(today) as total_today,\n",
        "    SUM(yesterday) as total_yesterday,\n",
        "    ROUND(SUM(avg_last_week), 0) as expected_avg,\n",
        "    ROUND(((SUM(today) - SUM(yesterday)) * 100.0 / SUM(yesterday)), 2) as dod_change_pct\n",
        "FROM checkout_1\n",
        "\n",
        "UNION ALL\n",
        "\n",
        "SELECT \n",
        "    'checkout_2' as dataset,\n",
        "    SUM(today) as total_today,\n",
        "    SUM(yesterday) as total_yesterday,\n",
        "    ROUND(SUM(avg_last_week), 0) as expected_avg,\n",
        "    ROUND(((SUM(today) - SUM(yesterday)) * 100.0 / SUM(yesterday)), 2) as dod_change_pct\n",
        "FROM checkout_2\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\nüìä QUERY 2: Compara√ß√£o de Totais Di√°rios\")\n",
        "print(\"=\"*60)\n",
        "comparison = pysqldf(query_comparison)\n",
        "display(comparison)"
      ],
      "metadata": {
        "id": "query2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# QUERY 3: An√°lise do hor√°rio de pico (10h-18h)\n",
        "query_peak = \"\"\"\n",
        "SELECT \n",
        "    c2.time,\n",
        "    c2.today as checkout_2_today,\n",
        "    c1.today as checkout_1_today,\n",
        "    c2.today - c1.today as difference,\n",
        "    CASE \n",
        "        WHEN c2.today = 0 THEN 'üî¥ OUTAGE'\n",
        "        WHEN c2.today < c1.today * 0.5 THEN 'üü† LOW'\n",
        "        WHEN c2.today > c1.today * 1.5 THEN 'üü° HIGH'\n",
        "        ELSE 'üü¢ NORMAL'\n",
        "    END as status\n",
        "FROM checkout_2 c2\n",
        "JOIN checkout_1 c1 ON c2.hour = c1.hour\n",
        "WHERE c2.hour BETWEEN 10 AND 18\n",
        "ORDER BY c2.hour\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n‚è∞ QUERY 3: An√°lise Hor√°rio de Pico (10h-18h)\")\n",
        "print(\"=\"*60)\n",
        "peak = pysqldf(query_peak)\n",
        "display(peak)"
      ],
      "metadata": {
        "id": "query3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# QUERY 4: Calcular Z-Score para checkout_2\n",
        "query_zscore = \"\"\"\n",
        "WITH stats AS (\n",
        "    SELECT \n",
        "        AVG(today) as mean_val,\n",
        "        AVG(today * today) - AVG(today) * AVG(today) as variance\n",
        "    FROM checkout_2\n",
        ")\n",
        "SELECT \n",
        "    c.time,\n",
        "    c.today,\n",
        "    ROUND(c.avg_last_week, 2) as expected,\n",
        "    ROUND((c.today - s.mean_val) / SQRT(s.variance), 2) as z_score,\n",
        "    CASE \n",
        "        WHEN ABS((c.today - s.mean_val) / SQRT(s.variance)) > 2.5 THEN 'üî¥ EXTREME'\n",
        "        WHEN ABS((c.today - s.mean_val) / SQRT(s.variance)) > 2 THEN 'üü† SIGNIFICANT'\n",
        "        WHEN ABS((c.today - s.mean_val) / SQRT(s.variance)) > 1 THEN 'üü° UNUSUAL'\n",
        "        ELSE 'üü¢ NORMAL'\n",
        "    END as z_interpretation\n",
        "FROM checkout_2 c\n",
        "CROSS JOIN stats s\n",
        "ORDER BY ABS((c.today - s.mean_val) / SQRT(s.variance)) DESC\n",
        "LIMIT 10\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\nüìà QUERY 4: Z-Score Analysis (Top 10 Desvios)\")\n",
        "print(\"=\"*60)\n",
        "zscore = pysqldf(query_zscore)\n",
        "display(zscore)"
      ],
      "metadata": {
        "id": "query4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìà 4. Visualiza√ß√µes Interativas"
      ],
      "metadata": {
        "id": "viz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gr√°fico 1: Compara√ß√£o checkout_1 vs checkout_2 (Plotly interativo)\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=(\n",
        "        'üìä checkout_1 - Dia Normal',\n",
        "        'üö® checkout_2 - Dia com Anomalia',\n",
        "        'üìâ Desvio da M√©dia (%)',\n",
        "        'üî• Heatmap de Compara√ß√£o'\n",
        "    ),\n",
        "    specs=[\n",
        "        [{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
        "        [{\"type\": \"bar\"}, {\"type\": \"heatmap\"}]\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Painel 1: checkout_1\n",
        "fig.add_trace(\n",
        "    go.Bar(x=checkout_1['time'], y=checkout_1['today'], name='Hoje', marker_color='#2ecc71'),\n",
        "    row=1, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=checkout_1['time'], y=checkout_1['avg_last_week'], name='M√©dia Semana', \n",
        "               line=dict(color='orange', dash='dash')),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Painel 2: checkout_2 com destaque na anomalia\n",
        "colors_2 = ['#e74c3c' if h in [15, 16, 17] else '#3498db' for h in checkout_2['hour']]\n",
        "fig.add_trace(\n",
        "    go.Bar(x=checkout_2['time'], y=checkout_2['today'], name='Hoje (Anomalia)', marker_color=colors_2),\n",
        "    row=1, col=2\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=checkout_2['time'], y=checkout_2['avg_last_week'], name='M√©dia Semana',\n",
        "               line=dict(color='orange', dash='dash'), showlegend=False),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# Painel 3: Desvio percentual\n",
        "checkout_2['deviation'] = ((checkout_2['today'] - checkout_2['avg_last_week']) / checkout_2['avg_last_week']) * 100\n",
        "colors_dev = ['#e74c3c' if d < -50 else '#f39c12' if d > 100 else '#2ecc71' for d in checkout_2['deviation']]\n",
        "fig.add_trace(\n",
        "    go.Bar(x=checkout_2['time'], y=checkout_2['deviation'], name='Desvio %', marker_color=colors_dev),\n",
        "    row=2, col=1\n",
        ")\n",
        "fig.add_hline(y=-50, line_dash=\"dash\", line_color=\"red\", row=2, col=1)\n",
        "fig.add_hline(y=100, line_dash=\"dash\", line_color=\"orange\", row=2, col=1)\n",
        "\n",
        "# Painel 4: Heatmap\n",
        "heatmap_data = pd.DataFrame({\n",
        "    'checkout_1': checkout_1['today'],\n",
        "    'checkout_2': checkout_2['today'],\n",
        "    'Diferen√ßa': checkout_2['today'] - checkout_1['today']\n",
        "}).T\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Heatmap(\n",
        "        z=heatmap_data.values,\n",
        "        x=checkout_1['time'],\n",
        "        y=['checkout_1', 'checkout_2', 'Diferen√ßa'],\n",
        "        colorscale='RdYlGn',\n",
        "        showscale=True\n",
        "    ),\n",
        "    row=2, col=2\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    height=800,\n",
        "    title_text=\"üîç CloudWalk Checkout Analysis - Detec√ß√£o de Anomalias\",\n",
        "    showlegend=True\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "viz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gr√°fico 2: Timeline do Incidente (foco no outage)\n",
        "fig2 = go.Figure()\n",
        "\n",
        "# Linha de ontem\n",
        "fig2.add_trace(go.Scatter(\n",
        "    x=checkout_2['time'],\n",
        "    y=checkout_2['yesterday'],\n",
        "    mode='lines+markers',\n",
        "    name='Ontem',\n",
        "    line=dict(color='#3498db', width=2, dash='dash'),\n",
        "    marker=dict(size=8)\n",
        "))\n",
        "\n",
        "# Linha de hoje\n",
        "fig2.add_trace(go.Scatter(\n",
        "    x=checkout_2['time'],\n",
        "    y=checkout_2['today'],\n",
        "    mode='lines+markers',\n",
        "    name='Hoje',\n",
        "    line=dict(color='#e74c3c', width=3),\n",
        "    marker=dict(size=10)\n",
        "))\n",
        "\n",
        "# Destacar zona de outage\n",
        "fig2.add_vrect(\n",
        "    x0=\"14h\", x1=\"18h\",\n",
        "    fillcolor=\"red\", opacity=0.2,\n",
        "    layer=\"below\", line_width=0,\n",
        "    annotation_text=\"üö® OUTAGE ZONE\",\n",
        "    annotation_position=\"top left\"\n",
        ")\n",
        "\n",
        "# Destacar zona de spike\n",
        "fig2.add_vrect(\n",
        "    x0=\"07h\", x1=\"10h\",\n",
        "    fillcolor=\"orange\", opacity=0.2,\n",
        "    layer=\"below\", line_width=0,\n",
        "    annotation_text=\"üìà SPIKE ZONE\",\n",
        "    annotation_position=\"top left\"\n",
        ")\n",
        "\n",
        "fig2.update_layout(\n",
        "    title=\"üö® Timeline do Incidente - checkout_2\",\n",
        "    xaxis_title=\"Hora\",\n",
        "    yaxis_title=\"Transa√ß√µes\",\n",
        "    height=500,\n",
        "    hovermode='x unified'\n",
        ")\n",
        "\n",
        "fig2.show()"
      ],
      "metadata": {
        "id": "viz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üö® 5. Resumo da Anomalia Detectada"
      ],
      "metadata": {
        "id": "summary"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular m√©tricas do incidente\n",
        "outage_hours = checkout_2[checkout_2['hour'].isin([15, 16, 17])]\n",
        "lost_transactions = outage_hours['avg_last_week'].sum()\n",
        "\n",
        "# Z-Scores\n",
        "mean_val = checkout_2['today'].mean()\n",
        "std_val = checkout_2['today'].std()\n",
        "checkout_2['z_score'] = (checkout_2['today'] - mean_val) / std_val\n",
        "\n",
        "print(\"\")\n",
        "print(\"‚ïî\" + \"‚ïê\"*60 + \"‚ïó\")\n",
        "print(\"‚ïë\" + \" üö® ANOMALIA CR√çTICA DETECTADA \".center(60) + \"‚ïë\")\n",
        "print(\"‚ï†\" + \"‚ïê\"*60 + \"‚ï£\")\n",
        "print(f\"‚ïë  Dataset: checkout_2.csv\".ljust(61) + \"‚ïë\")\n",
        "print(f\"‚ïë  Per√≠odo Afetado: 15:00 - 17:59 (3 horas)\".ljust(61) + \"‚ïë\")\n",
        "print(f\"‚ïë  Transa√ß√µes Registradas: ZERO\".ljust(61) + \"‚ïë\")\n",
        "print(f\"‚ïë  Transa√ß√µes Esperadas: ~{lost_transactions:.0f}\".ljust(61) + \"‚ïë\")\n",
        "print(f\"‚ïë  Z-Score M√°ximo: {checkout_2['z_score'].min():.2f}\".ljust(61) + \"‚ïë\")\n",
        "print(\"‚ï†\" + \"‚ïê\"*60 + \"‚ï£\")\n",
        "print(\"‚ïë  Causa Prov√°vel: Outage do Sistema de Pagamento\".ljust(61) + \"‚ïë\")\n",
        "print(\"‚ïë  Evid√™ncia Secund√°ria: Spike +574% √†s 08h (backlog)\".ljust(61) + \"‚ïë\")\n",
        "print(\"‚ïö\" + \"‚ïê\"*60 + \"‚ïù\")\n",
        "print(\"\")"
      ],
      "metadata": {
        "id": "incident_summary"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tabela de compara√ß√£o final\n",
        "print(\"\\nüìä COMPARA√á√ÉO FINAL:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "comparison_data = {\n",
        "    'M√©trica': ['Total Hoje', 'Total Ontem', 'Varia√ß√£o DoD', 'Horas Cr√≠ticas', 'Horas com Spike', 'Status'],\n",
        "    'checkout_1': [checkout_1['today'].sum(), checkout_1['yesterday'].sum(), \n",
        "                   f\"+{((checkout_1['today'].sum() - checkout_1['yesterday'].sum()) / checkout_1['yesterday'].sum() * 100):.1f}%\",\n",
        "                   0, 0, '‚úÖ NORMAL'],\n",
        "    'checkout_2': [checkout_2['today'].sum(), checkout_2['yesterday'].sum(),\n",
        "                   f\"{((checkout_2['today'].sum() - checkout_2['yesterday'].sum()) / checkout_2['yesterday'].sum() * 100):.1f}%\",\n",
        "                   3, 6, 'üö® ANOMALIA']\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "display(comparison_df)"
      ],
      "metadata": {
        "id": "final_comparison"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéØ 6. Conclus√£o\n",
        "\n",
        "### Achados Principais:\n",
        "\n",
        "1. **Anomalia Cr√≠tica**: 3 horas consecutivas (15h-17h) com ZERO transa√ß√µes no checkout_2\n",
        "\n",
        "2. **Impacto Estimado**: ~62 transa√ß√µes perdidas durante hor√°rio de pico\n",
        "\n",
        "3. **Evid√™ncia Estat√≠stica**: Z-Score de -2.8 confirma anomalia significativa\n",
        "\n",
        "4. **Padr√£o Secund√°rio**: Spike de +574% √†s 08h sugere processamento de backlog\n",
        "\n",
        "5. **Causa Prov√°vel**: Outage do sistema de pagamento entre 15h-17h\n",
        "\n",
        "---\n",
        "\n",
        "### üîó Links do Projeto Completo:\n",
        "\n",
        "- **GitHub**: [Link do Reposit√≥rio]\n",
        "- **Dashboard Grafana**: [Link do Dashboard]\n",
        "- **Podcast**: [Link do NotebookLM]\n",
        "\n",
        "---\n",
        "\n",
        "*\"Bombeiros que usam c√≥digo para apagar inc√™ndios.\"* üî•\n",
        "\n",
        "**Candidato:** S√©rgio  \n",
        "**Vaga:** Monitoring Intelligence Analyst (Night Shift)  \n",
        "**CloudWalk Challenge - Task 3.1**"
      ],
      "metadata": {
        "id": "conclusion"
      }
    }
  ]
}
