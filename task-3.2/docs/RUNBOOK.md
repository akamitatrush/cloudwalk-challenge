# ğŸ“˜ RUNBOOK - TRANSACTION GUARDIAN

## Guia de Resposta a Incidentes

---

## ğŸ“‘ ÃNDICE

1. [VisÃ£o Geral do Sistema](#1-visÃ£o-geral-do-sistema)
2. [Alertas e Respostas](#2-alertas-e-respostas)
3. [Procedimentos de DiagnÃ³stico](#3-procedimentos-de-diagnÃ³stico)
4. [AÃ§Ãµes de MitigaÃ§Ã£o](#4-aÃ§Ãµes-de-mitigaÃ§Ã£o)
5. [EscalaÃ§Ã£o](#5-escalaÃ§Ã£o)
6. [Contatos](#6-contatos)

---

## 1. VISÃƒO GERAL DO SISTEMA

### 1.1 Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API       â”‚â”€â”€â”€â–¶â”‚ Prometheus  â”‚â”€â”€â”€â–¶â”‚  Grafana    â”‚
â”‚  (8001)     â”‚    â”‚   (9091)    â”‚    â”‚   (3002)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                   â”‚Alertmanagerâ”‚
                   â”‚   (9093)   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 URLs de Acesso

| ServiÃ§o | URL | Credenciais |
|---------|-----|-------------|
| API Swagger | http://localhost:8001/docs | - |
| Grafana | http://localhost:3002 | admin/admin |
| Prometheus | http://localhost:9091 | - |
| Alertmanager | http://localhost:9093 | - |

### 1.3 MÃ©tricas Principais

| MÃ©trica | DescriÃ§Ã£o | Threshold |
|---------|-----------|-----------|
| `transaction_guardian_total` | Total de transaÃ§Ãµes | - |
| `transaction_guardian_anomalies` | Anomalias detectadas | < 10% |
| `transaction_guardian_current_count` | Volume atual | > 50 |
| `transaction_guardian_approval_rate` | Taxa de aprovaÃ§Ã£o | > 90% |

---

## 2. ALERTAS E RESPOSTAS

### ğŸš¨ ALERT: ZeroTransactions

**Severidade:** CRITICAL (P1)  
**CondiÃ§Ã£o:** `count == 0` por 1 minuto  
**Impacto:** PossÃ­vel outage total

#### DiagnÃ³stico

```bash
# 1. Verificar se API estÃ¡ respondendo
curl http://localhost:8001/health

# 2. Verificar mÃ©tricas
curl http://localhost:8001/stats | jq

# 3. Verificar logs
docker logs guardian-api --tail 50
```

#### AÃ§Ãµes Imediatas

1. âœ… Verificar status da API (`/health`)
2. âœ… Verificar upstream (payment gateway)
3. âœ… Verificar rede/conectividade
4. âœ… Verificar logs de erro
5. âš ï¸ Se necessÃ¡rio, escalar para P1

#### Comando de VerificaÃ§Ã£o RÃ¡pida

```bash
# VerificaÃ§Ã£o completa
curl -s http://localhost:8001/health && \
curl -s http://localhost:8001/stats | jq '.metrics'
```

---

### âš ï¸ ALERT: LowVolume

**Severidade:** WARNING (P2)  
**CondiÃ§Ã£o:** `count < 50` por 2 minutos  
**Impacto:** DegradaÃ§Ã£o do serviÃ§o

#### DiagnÃ³stico

```bash
# Ver histÃ³rico de volume
curl "http://localhost:9091/api/v1/query?query=transaction_guardian_current_count[5m]"

# Ver tendÃªncia
curl "http://localhost:9091/api/v1/query?query=rate(transaction_guardian_total[5m])"
```

#### AÃ§Ãµes Imediatas

1. âœ… Verificar se Ã© horÃ¡rio de baixo movimento
2. âœ… Comparar com histÃ³rico (mesmo dia/hora semana passada)
3. âœ… Verificar status dos gateways upstream
4. âš ï¸ Se persistir por 5+ min, escalar para CRITICAL

---

### âš ï¸ ALERT: HighAnomalyRate

**Severidade:** WARNING (P2)  
**CondiÃ§Ã£o:** `anomalias / total > 10%`  
**Impacto:** Qualidade das transaÃ§Ãµes

#### DiagnÃ³stico

```bash
# Ver anomalias recentes
curl "http://localhost:8001/anomalies?limit=20" | jq

# Ver distribuiÃ§Ã£o por tipo
curl http://localhost:8001/stats | jq '.metrics.status_counts'
```

#### AÃ§Ãµes Imediatas

1. âœ… Identificar tipo predominante de anomalia
2. âœ… Verificar se Ã© spike ou problema contÃ­nuo
3. âœ… Analisar padrÃ£o (horÃ¡rio, tipo de transaÃ§Ã£o)
4. âš ï¸ Investigar causa raiz

---

### ğŸš¨ ALERT: LowApprovalRate

**Severidade:** CRITICAL (P1)  
**CondiÃ§Ã£o:** `approval_rate < 90%` por 2 minutos  
**Impacto:** Perda de receita

#### DiagnÃ³stico

```bash
# Ver taxa de aprovaÃ§Ã£o atual
curl http://localhost:8001/stats | jq '.metrics.approval_rate'

# Ver distribuiÃ§Ã£o de status
curl http://localhost:8001/stats | jq '.metrics.status_counts'
```

#### AÃ§Ãµes Imediatas

1. âœ… Verificar qual status estÃ¡ aumentando (failed/denied/reversed)
2. âœ… Verificar auth_codes mais frequentes
3. âœ… Contatar equipe de payments
4. âš ï¸ Escalar se necessÃ¡rio

---

### âš ï¸ ALERT: VolumeSpike

**Severidade:** WARNING (P2)  
**CondiÃ§Ã£o:** `count > 200% da mÃ©dia`  
**Impacto:** PossÃ­vel sobrecarga ou ataque

#### DiagnÃ³stico

```bash
# Ver pico vs mÃ©dia
curl http://localhost:8001/stats | jq '{current: .metrics.current_count, avg: .metrics.avg_count}'

# Verificar se Ã© legÃ­timo (promoÃ§Ã£o, etc)
curl "http://localhost:8001/anomalies?limit=10" | jq
```

#### AÃ§Ãµes Imediatas

1. âœ… Verificar se hÃ¡ campanha/promoÃ§Ã£o ativa
2. âœ… Verificar se Ã© trÃ¡fego legÃ­timo
3. âœ… Monitorar recursos (CPU, memÃ³ria)
4. âš ï¸ Se suspeito, investigar possÃ­vel ataque

---

## 3. PROCEDIMENTOS DE DIAGNÃ“STICO

### 3.1 VerificaÃ§Ã£o de SaÃºde Geral

```bash
#!/bin/bash
# health_check.sh

echo "ğŸ” Transaction Guardian - Health Check"
echo "======================================="

# API
echo -n "API: "
curl -s http://localhost:8001/health | jq -r '.status'

# Prometheus
echo -n "Prometheus: "
curl -s http://localhost:9091/-/healthy && echo "OK" || echo "FAIL"

# Grafana
echo -n "Grafana: "
curl -s http://localhost:3002/api/health | jq -r '.database'

# Containers
echo ""
echo "Containers:"
docker ps --filter "name=guardian" --format "{{.Names}}: {{.Status}}"
```

### 3.2 Verificar MÃ©tricas

```bash
# Todas as mÃ©tricas
curl http://localhost:8001/metrics

# EstatÃ­sticas formatadas
curl http://localhost:8001/stats | jq

# Query especÃ­fica no Prometheus
curl "http://localhost:9091/api/v1/query?query=transaction_guardian_approval_rate"
```

### 3.3 Verificar Logs

```bash
# Logs da API
docker logs guardian-api --tail 100

# Logs com filtro de erro
docker logs guardian-api 2>&1 | grep -i error

# Logs do Prometheus
docker logs guardian-prometheus --tail 50

# Logs do Alertmanager
docker logs guardian-alertmanager --tail 50
```

### 3.4 Verificar Alertas Ativos

```bash
# No Prometheus
curl http://localhost:9091/api/v1/alerts | jq

# No Alertmanager
curl http://localhost:9093/api/v2/alerts | jq
```

---

## 4. AÃ‡Ã•ES DE MITIGAÃ‡ÃƒO

### 4.1 Reiniciar API

```bash
docker restart guardian-api

# Verificar se voltou
sleep 5
curl http://localhost:8001/health
```

### 4.2 Reiniciar Stack Completa

```bash
cd task-3.2/infrastructure
docker compose restart

# Verificar todos os serviÃ§os
docker ps --filter "name=guardian"
```

### 4.3 Rebuild da API

```bash
cd task-3.2/infrastructure
docker compose up -d --build guardian-api
```

### 4.4 Reset de MÃ©tricas

```bash
# Reset contadores (cuidado em produÃ§Ã£o!)
curl -X POST http://localhost:8001/reset
```

### 4.5 ForÃ§ar Reload do Prometheus

```bash
curl -X POST http://localhost:9091/-/reload
```

---

## 5. ESCALAÃ‡ÃƒO

### Matriz de EscalaÃ§Ã£o

| Severidade | Tempo para Ack | Tempo para Escalar | Para Quem |
|------------|----------------|-------------------|-----------|
| P1 (CRITICAL) | 5 min | 15 min | Tech Lead + Manager |
| P2 (WARNING) | 15 min | 30 min | Tech Lead |
| P3 (INFO) | 30 min | 2 horas | Equipe |

### Quando Escalar

- âŒ NÃ£o conseguiu identificar a causa em 15 min
- âŒ Impacto em clientes confirmado
- âŒ Precisa de acesso/permissÃ£o adicional
- âŒ Problema em sistema externo (gateway, etc)

### Template de EscalaÃ§Ã£o

```
ğŸš¨ ESCALAÃ‡ÃƒO - [SEVERIDADE]

Incidente: INC-YYYY-MMDD-XXX
InÃ­cio: HH:MM
DuraÃ§Ã£o: XX min

Impacto: [DescriÃ§Ã£o]
Causa: [Identificada/Investigando]
AÃ§Ãµes tomadas: [Lista]
Preciso de: [O que precisa]

cc: @oncall @techleads
```

---

## 6. CONTATOS

### Equipe On-Call

| FunÃ§Ã£o | Contato | HorÃ¡rio |
|--------|---------|---------|
| SRE On-Call | #sre-oncall | 24/7 |
| Payments Team | #payments | Business hours |
| Backend Team | #backend | Business hours |

### Canais Slack

| Canal | PropÃ³sito |
|-------|-----------|
| #incidents | Incidentes ativos |
| #incidents-critical | Apenas P1 |
| #monitoring-alerts | Alertas automÃ¡ticos |
| #transaction-guardian | DiscussÃµes do sistema |

---

## ğŸ“‹ CHECKLIST DE INCIDENTE

### Ao Receber Alerta

- [ ] Ler alerta e entender severidade
- [ ] Verificar dashboards no Grafana
- [ ] Executar diagnÃ³stico bÃ¡sico
- [ ] Comunicar no canal apropriado

### Durante InvestigaÃ§Ã£o

- [ ] Documentar timeline
- [ ] Coletar evidÃªncias (logs, mÃ©tricas)
- [ ] Identificar causa raiz
- [ ] Aplicar mitigaÃ§Ã£o

### PÃ³s-ResoluÃ§Ã£o

- [ ] Confirmar mÃ©tricas normalizadas
- [ ] Atualizar canal com resoluÃ§Ã£o
- [ ] Criar ticket de follow-up
- [ ] Agendar post-mortem se P1/P2

---

*Runbook Version: 1.0*  
*Last Updated: 2025-01-19*  
*Owner: Monitoring Team*
